# IRISDS
Fisher's Iris data Set Project

First published in the 'Annals of Eugenics' in 1936, by statistician and botanist Sir Ronal Aylmer Fisher, Fisher's Data Set has been a staple data set studied by students and hobbyists in the statistics computer science and related fields.
The dataset itself comprises of 5 key attributes: sepal length, sepal width, petal length, petal width and species, measured in cm from 150 different samples, each collected from "from the same pasture, and picked on the same day and measured at the same time by the same person with the same apparatus".  The data was collected by Dr. Edgar Anderson, an American botanist, at the Gaspé Peninsula in Canada.
Edgar Anderson (1935). "The irises of the Gaspé Peninsula". Bulletin of the American Iris Society. 59: 2–5. (https://en.wikipedia.org/wiki/Iris_flower_data_set)
The data is collected from three individual species of Iris: Iris Setosa, Iris Virginica and Iris Versicolor, and from the results Fisher was able to develop a linear discriminant model to distinguish each species from the others. 

Regarding the process of completing the project, I feel I had very little understanding of how to approach the project form the outset and a lack of experience in tackling such task was made increasingly obvious the further I followed through on the process.
In the beginning I used Corey Schafer’s youtube channel to come to terms with a the subject matter and core concepts of python and their application to the datset. 
https://www.youtube.com/channel/UCCezIgC97PvUuR4_gbFUs5g 

As part of the initial the code written I had defined functions to pull through the data I thought would be relevant to the project, adding everything to a list and generally creating clunky, but effective code. As would be a theme for the duration of my work of the project, the more I read online about each topic, the greater variety of possible solutions I found, my initial assumption of get working code and then clean the code up was just not as viable as had previously been thought. I spent far too long working like this and really achieving nothing of any substance other than a feeling of impending doom. In this time I did not upload anything to my repository in Github, believing the work would look foolish, this is a major regret I feel the evolution of the project from start to finish is poorly reflected
•	Summary of the Dataset
As mentioned above, the initial code written for this project was very clunky, as my knowledge 
of pandas in particular grew, I was consistently throwing away previous work and essentially starting from afresh.  The summary file I have provided as part of my project, I am relatively content that this is the appropriate method to use, I will use the .describe() method to gauge all future datasets. It will be most likely be one of the commands passed on new data. The code itsef is pretty self-explanatory, I opened the csv file with pandas and created a dataframe (df), filtered the dataframe , from the I was able to apply the .describe() method, and a few attempts with .to_dict() and .to_list(), I settled on .to_string() in order to write the df to a .txt file to resemble a table. The rest was basic formatting, if I had more time, I would have liked to figure out a possible method to automate the writing to the txt file. I again used Corey Schafer’s videos and playlists for pretty much the whole basis of my initial understanding.
https://www.youtube.com/watch?v=Lw2rlcxScZY&list=PL-osiE80TeTsWmV9i9c58mdDCSskIFdDS&index=4

•	Histogram & Scatterplots
So as I began looking into how I would complete this part of the project I initially thought
that creating lists from the df and then just making a formula for the two graphs and feeding in my lists was the best course of action, this is still very evident in the final submission, I will ensure you it is through no lack of trying to remove this evidence, however, a functional(or somewhat) code is better than one that does not work. I know that the is a df.hist() method, however what I had in mind was using a dictionary and iterating through these dict to produce separate histograms for each species also, however, my code was not quite right,  and I could not get to the bottom of it in time.
Histogram code – so the code works by creating a number of lists in a very overly convoluted method. I went with subplots as I believe using this method was cleaner and would show a greater level of research and understanding. 
ax = np.ravel(ax2d)  – this essentially unravels the 2d nature of the subplot, as I could not for the life of me get the rest of the code to fit in comfortably, given more time I am sure I would’ve figured it out. https://www.youtube.com/watch?v=fIFDI7bWNpA&feature=youtu.be&t=485
for count, p in enumerate(allspecies): - I believe the source for this was the same video referenced above. Enumerate the list ‘allspecies’ and then use the count value to iterate ovr each ax[] to create the plots. I think it worked ok for one list of values, I tried to complete this for a list of lists (toplvlist) however this again would not work out in time.
I think the rest of the code for histograms is not overly complex and was just a matter of trial and error to get the right formatting for me. 
I am still not happy to be submitting the histogram piece, as I feel I was close to structuring the syntax in my head, however needs must.
Scatterplot – the reason I went with the lists I the beginning is because I was sure this would make the scatterplot  very easy, and to a degree I was correct, form a rookie to codings perspective it was the correct choice, however, I am sure there is a better way to map this out in numpy or pandas.
As above I used pyplot to have both images on the same page, no need to use the ravel method as it was a 1d plane and then just finish out the formatting of the graph. I also think a dictionary would let me include a for loop in this to automate the lines for ax[1], but needs they must be.

